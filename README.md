# vr-project

### AR Data Visualization Application
Megan Smith + Milly Attree

### The Idea/Motivation/Proposed Outcome
**Idea:** An AR application which can be downloaded onto the users phone. The phone is pointed at an image (graph, chart, etc.) on a piece of paper, and then the app loads the 3D visualization. The user will be able to point the app at different images to display various data visualizations of varying complexity, and choose menu items in order to display the data set in different graph types.

**Motivation:** Data visualization, at it's core, communicates data sets in a way that viewers are easily able to understand the relationships in the data. For many people, it is easier to understand a bar or line graph than extrapolate meaning from a chart of numbers. This project will display important information relevant to pandemics (current and past), and by doing so will help people identify new relationships in these pandemics, or simply understand pandemic trends and why they occur. The core motivation, then, is not only to create a tool for education but also to advance the speed at which students, researchers and the world in general can read the trends of a pandemic.  

**Proposed Outcome:** To create a fully-functional educational tool with a minimum of 4 different graphs that allow for compare/contrast evaluations. A visually appealing, user-friendly application that allows greater comprehension of pandemeics, past and present.  


### Interaction Techniques
**Menu for pandemics** The VR user has the opportunity to utilize a menu inside the app. This menu gives the user control over which pandemic data set they can view, which will range from coronavirus, Spanish flu, ebola, MERS, SARS etc. Each of these data sets will include a category for the infected, recovered and death rates from the selected pandemic (along the x axis), how many people fell into the aforementioned three categories (y axis) over a range of months (z axis.)

**Menu for type of data visualization** The user will have the option to see the data their chart of choice, such as bar graph, line graph, etc. The user will be able to go back and forth between these option at will to gain more clarity about the numbers.

**See different angles through phone** The user will be able to move closer (or zoom in and out) of the data visualization, as well as view the model at different angles.

**Potential Future Scope Items** The user could get more information about a data point by pointing to a dot or tap on it on the smartphone screen.

### Outline of Planned Implementation
**Personas, User Research, Storyboards**
*  Who is our target group for this simulation, who is the most likely to use it?
*  What do users actually want, what are they looking for? What do they want to achieve or learn from this simulation?
* Whatâ€™s a scenario where this might help the user, what scenario will this type of application be useful?

**Collection of data**
* Collecting data that is relevant and important to the user
* Collecting data that makes it easy to draw conclusions about events and extrapolate the relevant information
* Collecting data that is able to be compared
* Collecting data that is able to be compared
* Collecting data that is able to be compared

**Visual Design**
* Design of the chart (colors, width, transparency) keeping in mind what will make it most clear for the user
* Design of the navigation menu (making things user-friendly, on-brand)
* Design something that is not only informative but sharp/modern
* Design with interaction in mind (bars moving up and down,

**Implementation in Unity**
* Designing the graphs with relevant in data in Unity
* Creating navigable menu
* Creating a function that allows the application to recognize the image it's being pointed at, then to load the relevant graph
* Creating a camera view that allows the user to walk around and view the graphs at different angles
* Downloading the AR app to a phone (or otherwise using the HoloLens)

**Testing**
* What does the user like/dislike?
* What should be changed and why?
* How interactable is the prototype?
* Does it work as expected?
* What can we improve/take out to make it easier to understand?

**Implementation in Unity**
* Taking lessons learned from user testing and implementing those changes

**Final delivery**
* Documentation
* Presentation
*

![Example1](https://i.ytimg.com/vi/9WC4oSP_OCE/hqdefault.jpg)

![Example 2](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT2ILbw6kYYVYugyADr1x03ELB-j9eofoE9ww&usqp=CAU)
