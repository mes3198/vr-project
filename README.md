# vr-project

### Coronavirus VR Simulation: Cover Your Cough
The Team is Comprised of:
Me, Myself and I
### The Idea/Motivation/Proposed Outcome
**Idea:** A VR Simulation that follows the trajectory of respitatory droplets ejected from sneezing and coughing. The 

**Motivation:** The CDC recommends staying 6 feet apart to limit the spread of coronavirus. Why? Current science suggests that the coronavirus spreads through large respiratory droplets that are ejected into the air when we sneeze, cough or even sing/speak loudly. Even though this is common knowledge now, it is sometimes easy to fall back into the routine of standing too close to each other whether in line at the bakery or brainstorming ideas in class. Visual representations make 

**Proposed Outcome:** An immersive VR experience wherin the Viewer is placed at a cafe table with two VR people. Person A sneezes all over the table. Over the course of 2-3 minutes, the Viewer can follow the trajectory of the droplets as they land all over the cafe table (and it's cups, food and other accoutrements) as well as Person B sitting across that table. It's pretty gross admittedly, but it will hit home the WHY of why we have to keep our distance. 


### Interaction Techniques
**Set the scene** The VR user has the opportunity to change up the scene on the table. Any object on the table can be moved closer or farther from Person A (the sneezer.)

**Sneeze or cough? Mask or no mask?** The user will have 4 options: what is the respiratory droplet trajectory from a sneeze or cough? What is the trajectory when Person A has a mask on? How much contamination is caused then? The user will have the opportunity to play with these different settings to enhance the understanging of how important wearing a mask is.

**Change the timeline**Once an option is selected, the VR user will have the option to speed up or slow down how long it takes for droplets to settle. (Some are larger and will fall more quickly, others are smaller and will take more time to fall.) Instead of waiting several minutes for all droplets to fall to see the final result, the user can skip to the end to see what the final scene looks like 

**Navigation through phone:** 

### Outline of Planned Implementation
**Personas, User Research, Storyboards**
*  Who is our target group for this AR, who is the most likely to use it?
*  What do users actually want, what are they looking for? 
* What’s a scenario where the AR might help the user, what scenario will this type of application be useful?

**Collection of statistics**
* At this point we determine exactly which statistics we will represent in the app
* Where are we targeting (which states, which cities, etc.)
* What pandemic data sets from this and other pandemics (deaths, positive tests, recovery, etc.)

**Visual Design**
* Designing how these statistics are going to look like
* What is the best way to represent them (what color, are they transparent, etc.)
* How “3D” do we make the representation?
* What values do we use to make the data sets comparable?
**Implementation in Unity**
* Inputting these statistics into Unity
* Implementing the visual design
* Necessary coding to make it interactive

**Testing**
* What does the user like/dislike?
* What should be changed and why?
* How interactable is the prototype?
* Does it work as expected?
* What can we improve/take out to make it easier to understand?

**Implementation in Unity**
* Taking lessons learned from user testing and implementing those changes

**Final delivery**
* Documentation
* Presentation

![Example1](https://www.meetingsnet.com/sites/meetingsnet.com/files/styles/article_featured_retina/public/augmentedreality.jpeg?itok=b5my43ZQ)

![Example 2](http://jolamux.com/master/img/ar/dataViz/img-AR-data-final-11.jpg)
